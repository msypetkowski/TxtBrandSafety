\documentclass[a4paper]{article}

\usepackage[a4paper,  margin=1.0in]{geometry}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}


\usepackage[utf8]{inputenc}
\begin{document}


\title{Text-based brand safety system}

\author{Mikołaj Ciesielski, Bartosz Paszko, Michał Sypetkowski}
\maketitle

\section{General information}

The system provides brand safety functionality --
answer queries with a html document as an argument.
The answer is vector of advertisement types compatibilities.
These values can be thresholded for discrimination of incompatible
ads or for selecting best ads for the given website.


Git hub repository: \url{https://github.com/msypetkowski/TxtBrandSafety}.

Most important tools and languages:
\begin{itemize}
    \item \textbf{Python}\footnote{\url{https://www.python.org/}}
        - the whole project is written in python
    \item \textbf{NumPy}\footnote{\url{http://www.numpy.org/}}
    \item \textbf{scikit-learn}\footnote{\url{http://scikit-learn.org/stable/index.html}}
    \item \textbf{nltk}\footnote{\url{https://www.nltk.org/}}
    \item \textbf{gensim}\footnote{\url{https://radimrehurek.com/gensim/}}
    \item \textbf{flask}\footnote{\url{http://flask.pocoo.org/}}
\end{itemize}


\section{Discriminator}
In text processing system, we use ready word embeddings --
\texttt{word2vec} is made with Google News data (it has 3 million 300-dimension English word vectors).


We support the following advertisement types:
\begin{enumerate}
    \item alcohol
    \item food
    \item electronics
    \item jobs
    \item online games
\end{enumerate}

We support the following website types:
\begin{enumerate}
    \item alcohol
    \item food
    \item electronics
    \item jobs
    \item online games
\end{enumerate}

All this data is defined in \texttt{data/metadata.json}, and can be easily modified there.
For each website type we created small datasets using text fragments from real websites.
There are JSON files in \texttt{data} directory corresponding to particular website types
(e.g. \texttt{data/alcohol.json}).


\subsection{Website classification}

Let's call a text fragment extracted from website a document.
% For each document class $c_i\in{C}$, we have a list of keywords:
% \begin{equation}
%     (k_{i,1}, k_{i,2}, \ldots, k_{i, n_i})
% \end{equation}
For each document, we are able to calculate "content" (real number) of a given keyword,
We do that using our embeddings -- gensim library provides similarity methods for 2 words.
We calculate mean similarity for each word in the document to the keyword.

% We concatenate keywords lists from all defined classes:
% \begin{equation}
%     (k_{1,1}, k_{1,2}, \ldots, k_{1, n_1},
%     k_{2,1}, k_{2,2}, \ldots, k_{2, n_2},
%     \ldots,
%     k_{|C|,1}, k_{|C|,2}, \ldots, k_{|C|, n_{|C|}})
% \end{equation}
Then we treat "contents" of the keywords as attributes of classification example.
We create training examples from small manually created dataset - one training example from one text in dataset.

Then we feed these training examples into a classifier.
We tried SVM and naive Bayes classifiers.
Best results were achieved by SVM (90\% accuracy - measured with 5 fold cross-validation).

\subsection{Measuring advertisement compatibility}
\label{mainlogic}

Let $T$ be set of advertisement types and $C$ -- set website types.
We manually define a cost matrix $C(t, c)$ 
with $|T|$ rows and $|C|$ columns.
The matrix defined is in file \texttt{data/metadata.json},
and can be easily modified. Default matrix is shown in table \ref{table:costmx}.

\begin{table}[!hbt]
    \caption{Manually defined default cost matrix.
    \label{table:costmx}
    }
\footnotesize
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
    \hline
        & shop alcohol & general store  & "electronic shop \\
    \hline
          alcohol & 0& 0.5&   1 \\
    \hline
        food & 0.2&   0&   1 \\
    \hline
        electronics & 0.5& 0.5&   0 \\
    \hline
        jobs & 0.2& 0.2& 0.2 \\
    \hline
          online games & 1&   1& 0.2 \\
    \hline
    \end{tabular}
\end{center}
\end{table}

Discrimination can be performed for each advertisement type $t$
by thresholding the following sum:
\begin{equation}
    \sum_{c\in{C}} {C(t, c) \cdot P(c)}
\end{equation}
where $P(c)$ is predicted probability of the text document having type $c$.



\subsection{Website classification and compatibility measurement benchmark}

We prepared a script for measuring website classification and
advertisement compatibility.
It is implemented \texttt{test.py}.

The benchmark is divided into 3 tests:
\begin{enumerate}
    \item \texttt{shop\_alcohol} website class test --
        we assumed best advertisement type as \texttt{alcohol},
        and banned should be \texttt{online\_games}.
    \item \texttt{general\_store} website class test --
        we assumed best advertisement type as \texttt{food},
        and banned should be \texttt{online\_games}.
    \item \texttt{electronic\_shop} website class test --
        we assumed best advertisement type as \texttt{electronics},
        and banned should be \texttt{alcohol} and \texttt{food}.
\end{enumerate}
For each test, we prepare 10 website examples.


\subsubsection {Website classification results}
Predicted website class probabilities for each tested document are shown in
tables
\ref{table:res1},
\ref{table:res2} and
\ref{table:res3}.

As we can see, the results are satisfactory event with our very small dataset
that was created manually in a few minutes.
SVM works well in general on small datasets -- has efficient generalization.
We use keywords contents as attributes, so maximizing decision margins (like SVM does)
seems to be a good idea in a common sense.

\subsubsection {Advertisement compatibility measurement results}
We consider ads banned if the compatibility value is below 0.4.
Best ad is defined as an ad with highest compatibility.
Best ad accuracy is simply a a ratio of correct predictions
of the most compatible ads to their total amount.
Banned ads accuracy is calculated with Jaccard index.
Jaccard index is given by:
\begin{equation}
    J(A,B) = \frac{|A\cap B|}{|A\cup B|}
\end{equation}
where A is a set of ads that should be banned and B is a set of ads that were predicted to be banned.
The results are shown in table \ref{table:testResults}.


\begin{table}[!hbt]
    \caption{ Summary of the experiment accuracy results
    \label{table:testResults}
    }
\footnotesize
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
    \hline
        Alcohol shop ground truth class experiment best ad accuracy:  &
        0.9 \\
        Alcohol shop ground truth class experiment banned ads accuracy: &
        1.0 \\
    \hline
        General store ground truth class experiment best ad accuracy: &
        0.9 \\
        General store ground truth class experiment banned ads accuracy: &
        0.95 \\
    \hline
        Electronic shop ground truth class experiment best ad accuracy: &
        0.9 \\
        Electronic shop ground truth class experiment banned ads accuracy: &
        0.9 \\
    \hline
        Total best ad accuracy & 0.9 \\
        Total banned ads accuracy & 0.95 \\
    \hline
    \end{tabular}
\end{center}
\end{table}


\section{Services/Agents}
Our whole system is stateless.
We have 2 types of services.
Our system architecture is in practice perfectly scallable (horizontally).

\subsection{Front service}

This service accepts queries from client applications.
The query argument is the website body (html code).
The response is a list of compatibility coefficients for predefined advertisement types.
The website code is passed to randomly selected (for load balancing) worker service.

There can be only one such agent in the system.
See the project's \texttt{README.md} for deployment instructions.


\subsection{Worker service}
A website is represented by it's html code.
This service extracts raw text from it and answer queries by returning vector of length of advertisement types
(with respective compatibilities).
It basically implements our whole logic (see section \ref{mainlogic}).

This service can be deployed on multiple machines in multiple instances.
See the project's \texttt{README.md} for deployment instructions.

\subsection {Performance benchmark}

We tested performance with single and 2 worker services.
We ran script \texttt{performance\_test.sh} using 1,2 and 3 workers.
It sends parallelly 100 queries.
We used html documents of sizes 138KB and 24KB.
Results are shown in table \ref{table:perf}.
In case of smaller query, the processing time is roughly proportional to the workers count,
therefore our business functionality can be efficiently scaled horizontally.

\begin{table}[!hbt]
    \caption{ System performance measurement results (real time in seconds)
    \label{table:perf}
    }
\footnotesize
\begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
    \hline
        query size & 1 worker & 2 workers & 3 workers\\
    \hline
        138KB & 36.132s&20.380s&13.606s\\
    \hline
        24KB &11.425s&6.795s&3.984s\\
    \hline
    \end{tabular}
\end{center}
\end{table}

\appendix
\section{Detailed website classification benchmark results tables}
% \label{singleResults}
% \input{singleResults}
\input{detailedResults}

\end{document}

