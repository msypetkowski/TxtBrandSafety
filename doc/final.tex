\documentclass[a4paper]{article}

\usepackage[a4paper,  margin=1.0in]{geometry}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}


\usepackage[utf8]{inputenc}
\begin{document}


\title{Text-based brand safety system}

\author{Mikołaj Ciesielski, Bartosz Paszko, Michał Sypetkowski}
\maketitle

\section{General information}

The system provides brand safety functionality --
answer queries with a html document as an argument.
The answer is vector of advertisement types cmpatibilities.
These values can be thresholded for discrimination of incompatible
ads or for selecting best ads for the given website.


Git hub repository: \url{https://github.com/msypetkowski/TxtBrandSafety}.

Most important tools and languages:
\begin{itemize}
    \item \textbf{Python}\footnote{\url{https://www.python.org/}}
        - the whole project will be written in python
    \item \textbf{NumPy}\footnote{\url{http://www.numpy.org/}}
    \item \textbf{scikit-learn}\footnote{\url{http://scikit-learn.org/stable/index.html}}
    \item \textbf{nltk}\footnote{\url{https://www.nltk.org/}}
    \item \textbf{gensim}\footnote{\url{https://radimrehurek.com/gensim/}}
    \item \textbf{flask}\footnote{\url{http://flask.pocoo.org/}}
\end{itemize}


\section{Discriminator}
In text processing system, we use ready word embeddings --
\texttt{word2vec} is made with Google News data (it has 3 million 300-dimension English word vectors).


We support the following advertisement types:
\begin{enumerate}
    \item alcohol
    \item food
    \item electronics
    \item jobs
    \item online games
\end{enumerate}
These are defined in \texttt{data/metadata.json}, and can be easily changed there.

We support the following website types:
\begin{enumerate}
    \item alcohol
    \item food
    \item electronics
    \item jobs
    \item online games
\end{enumerate}

For each website type we created small datasets using text fragments from real websites.
Let $T$ be set of advertisement types and $C$ -- set website types.


\subsection{Website classification}

Let's call a text fragment extracted from website a document.
% For each document class $c_i\in{C}$, we have a list of keywords:
% \begin{equation}
%     (k_{i,1}, k_{i,2}, \ldots, k_{i, n_i})
% \end{equation}
For each document, we are able to calculate "content" (real number) of a given keyword $k$,
We do that using our embeddings -- gensim library provides similarity methods for 2 words.
We calculate mean similarity for each word in the document to the keyword.

% We concatenate keywords lists from all defined classes:
% \begin{equation}
%     (k_{1,1}, k_{1,2}, \ldots, k_{1, n_1},
%     k_{2,1}, k_{2,2}, \ldots, k_{2, n_2},
%     \ldots,
%     k_{|C|,1}, k_{|C|,2}, \ldots, k_{|C|, n_{|C|}})
% \end{equation}
Then we treat "contents" of the keywords as attributes of classification example.
We create training examples from small manually created dataset - one training example from one text in dataset.

Then we feed these training examples into a classifier.
We tried SVM and naive bayes classifiers.
Best results were achieved by SVM (90\% accuracy - measured with 5 fold cross-validation).


\subsection{Measuring advertisement compatibility}
\label{mainlogic}

We manually define a cost matrix $C(t, c)$ 
with $|T|$ rows and $|C|$ columns.
The matrix defined is in file \texttt{data/metadata.json},
and can be easily changed.

We perform discrimination for each advertisement type $t$
by thresholding the following sum:
\begin{equation}
    \sum_{c\in{Y}} {C(t, c) \cdot P(c)}
\end{equation}
where $P(c)$ is predicted probability of the text document having type $c$.



\section{Services/Agents}
Our whole system is stateless.
We have 2 types of services.
Our system architecture is perfectly scallable (horizontally).

\subsection{Front service}

This service accepts queries from client applications.
The query argument is the website body (html code).
The response is a list of compatibility coeficients for predefined advertisement types.
The website code is passed to randomly selected (for load balancing) worker service.
See the project's `README.md` for deployment instructions.


\subsection{Worker service}
A website is represented by it's html code.
This service extacts raw text from it and answer queries by returning vector of length of advertisement types
(with respective compatibilities).
It basically implements our whole logic (see section \ref{mainlogic}.
See the project's `README.md` for deployment instructions.


\end{document}
